/**
 * ===========================================
 * SERVICIO DE CHAT H√çBRIDO - NORBOY
 * ===========================================
 *
 * Sistema inteligente que decide:
 * 1. Si hay match en la base de conocimiento local ‚Üí responde sin IA
 * 2. Si la pregunta es compleja o no hay match ‚Üí usa OpenAI
 * 3. Si OpenAI falla ‚Üí fallback a base de conocimiento
 */

const logger = require('../utils/logger');
const config = require('../config');
const aiProvider = require('../providers/ai');
const knowledgeBase = require('../knowledge');
const knowledgeUploadService = require('./knowledge-upload.service');
const conversationStateService = require('./conversation-state.service');
const escalationService = require('./escalation.service');
const embeddingsService = require('./embeddings.service'); // ‚úÖ NUEVO: B√∫squeda vectorial
const ragOptimized = require('./rag-optimized.service'); // ‚úÖ NUEVO: RAG Optimizado
const contextDetector = require('./context-detector.service'); // ‚úÖ CR√çTICO: Detector de contexto
const scheduleConfig = require('./schedule-config.service'); // ‚úÖ NUEVO: Configuraci√≥n din√°mica de horario

// Inicializar base de conocimiento
knowledgeBase.initialize();

// Flag para saber si OpenAI est√° disponible
let openAIAvailable = true;

// ‚úÖ NUEVO: Flag para habilitar/deshabilitar b√∫squeda vectorial
const USE_EMBEDDINGS = process.env.USE_EMBEDDINGS !== 'false'; // Por defecto: true

// ===========================================
// ‚úÖ NUEVO: ENRIQUECIMIENTO DE QUERIES DE SEGUIMIENTO
// ===========================================

/**
 * Detecta si una pregunta es de seguimiento y la enriquece con contexto previo.
 * Esto mejora la b√∫squeda RAG para preguntas cortas como "y cu√°ndo?", "d√≥nde es?"
 *
 * @param {string} message - Mensaje actual del usuario
 * @param {string} userId - ID del usuario
 * @returns {string} Query enriquecida para RAG (o el mensaje original si no es seguimiento)
 */
const enrichQueryWithContext = (message, userId) => {
  const normalized = message.toLowerCase().trim();
  const words = normalized.split(/\s+/);

  // Solo enriquecer si la pregunta es corta (‚â§ 8 palabras)
  if (words.length > 8) {
    return message;
  }

  // Indicadores de pregunta de seguimiento
  const followUpStarters = [
    'y ', 'pero ', 'entonces ', 'tambien ', 'tambi√©n ',
    'cuando', 'cu√°ndo', 'donde', 'd√≥nde', 'como', 'c√≥mo',
    'quien', 'qui√©n', 'cual', 'cu√°l', 'cuanto', 'cu√°nto',
    'que ', 'qu√© ', 'a que', 'a qu√©'
  ];

  const followUpPronouns = [
    'eso', 'esa', 'ese', 'esto', 'esta', 'este',
    'lo mismo', 'igual', 'otra vez', 'm√°s', 'mas'
  ];

  const isFollowUp = followUpStarters.some(s => normalized.startsWith(s)) ||
    followUpPronouns.some(p => normalized.includes(p)) ||
    (words.length <= 4 && normalized.endsWith('?'));

  if (!isFollowUp) {
    return message;
  }

  // Obtener los √∫ltimos mensajes de la conversaci√≥n
  try {
    const conversation = conversationStateService.getConversation(userId);
    if (!conversation || !conversation.messages || conversation.messages.length < 2) {
      return message;
    }

    // Tomar los √∫ltimos 4 mensajes (2 intercambios user/bot)
    const recentMessages = conversation.messages
      .filter(m => m.timestamp >= Date.now() - 10 * 60 * 1000) // √∫ltimos 10 min
      .slice(-4);

    if (recentMessages.length === 0) {
      return message;
    }

    // Extraer keywords de los mensajes recientes del usuario
    const stopWords = new Set([
      'el', 'la', 'los', 'las', 'un', 'una', 'unos', 'unas',
      'de', 'del', 'en', 'con', 'por', 'para', 'al', 'a',
      'y', 'o', 'que', 'es', 'son', 'fue', 'ser', 'hay',
      'me', 'te', 'se', 'nos', 'le', 'lo', 'su', 'mi',
      'si', 'no', 'm√°s', 'muy', 'ya', 'como', 'pero',
      'hola', 'gracias', 'ok', 'bueno', 'bien', 'sumerc√©'
    ]);

    const contextKeywords = recentMessages
      .filter(m => m.sender === 'user')
      .map(m => m.message)
      .join(' ')
      .toLowerCase()
      .replace(/[¬ø?!¬°.,;:()"']/g, '')
      .split(/\s+/)
      .filter(w => w.length > 2 && !stopWords.has(w))
      .slice(0, 6); // m√°ximo 6 keywords

    if (contextKeywords.length === 0) {
      return message;
    }

    // Combinar pregunta actual con keywords del contexto
    const enrichedQuery = `${message} ${contextKeywords.join(' ')}`;
    logger.info(`üîó Query enriquecida con contexto: "${message}" ‚Üí "${enrichedQuery}"`);

    return enrichedQuery;
  } catch (error) {
    logger.debug(`‚ö†Ô∏è Error enriqueciendo query: ${error.message}`);
    return message;
  }
};

// ===========================================
// SEGUIMIENTO DE CONSENTIMIENTO DE USUARIOS
// ===========================================
const userInteractionCount = new Map(); // userId ‚Üí n√∫mero de interacciones
const userConsent = new Map(); // userId ‚Üí boolean (acept√≥ o no)
const userConsentRequested = new Map(); // userId ‚Üí boolean (ya se mostr√≥ mensaje)
const pendingMessages = new Map(); // userId ‚Üí mensaje pendiente (para responder despu√©s de aceptar)

/**
 * Genera una respuesta de chat (H√çBRIDO)
 */
const generateTextResponse = async (userId, message, options = {}) => {
  try {
    const normalizedMessage = message.toLowerCase().trim();
    logger.debug(`Procesando: "${message.substring(0, 50)}..."}`);

    // ===========================================
    // VERIFICACI√ìN DE CICLO DE 60 MINUTOS
    // ===========================================
    const wasReset = conversationStateService.checkAndUpdateCycle(userId);

    if (wasReset) {
      // Si el ciclo expir√≥, resetear TODAS las variables de consentimiento
      logger.info(`üîÑ Ciclo reseteado para ${userId}, limpiando TODO el estado`);
      resetUserState(userId);

      // Indicar que se debe enviar bienvenida y consentimiento nuevamente
      // Esto har√° que en la siguiente interacci√≥n se vuelva a mostrar el flujo completo
    }

    // ===========================================
    // SISTEMA DE CONSENTIMIENTO
    // ===========================================

    // Incrementar contador de interacciones (solo si no es skipConsent)
    const currentCount = options.skipConsent
      ? (userInteractionCount.get(userId) || 0)
      : (userInteractionCount.get(userId) || 0) + 1;

    if (!options.skipConsent) {
      userInteractionCount.set(userId, currentCount);
      conversationStateService.incrementInteractionCount(userId);
      logger.info(`üí¨ Usuario ${userId}: Interacci√≥n #${currentCount}`);
    }

    // ===========================================
    // IMPORTANTE: NO evaluar escalaci√≥n aqu√≠
    // La escalaci√≥n se maneja en messageProcessor
    // Aqu√≠ solo intentar responder
    // ===========================================

    // Si es la SEGUNDA interacci√≥n y no ha respondido consentimiento, mostrar mensaje
    if (currentCount === 2 && !userConsent.has(userId) && !userConsentRequested.get(userId) && !options.skipConsent) {
      logger.info('üìã Segunda interacci√≥n, solicitando consentimiento');
      userConsentRequested.set(userId, true);

      // Guardar el mensaje para responderlo despu√©s de que acepte
      pendingMessages.set(userId, message);
      logger.info(`üìù Mensaje pendiente guardado: "${message.substring(0, 50)}..."`);

      return getConsentMessage(userId);
    }

    // Si NO ha aceptado el consentimiento, no responder
    if (userConsent.get(userId) === false && !options.skipConsent) {
      logger.info('üö´ Usuario rechaz√≥ consentimiento, no responde');
      return null; // No responder
    }

    // Si a√∫n no ha aceptado (esperando respuesta a botones), no procesar
    if (currentCount > 2 && !userConsent.has(userId) && !options.skipConsent) {
      logger.info('‚è≥ Esperando respuesta de consentimiento');
      return null;
    }

    // ===========================================
    // ‚úÖ CR√çTICO: DETECTAR CONTEXTO ANTES DE TODO
    // ===========================================
    const contextResult = contextDetector.detectContext(message);

    logger.info(`üîç Contexto detectado: ${contextResult.type} (NORBOY: ${contextResult.isNorboyRelated})`);

    // Si NO es sobre NORBOY ‚Üí Mensaje restrictivo inmediato
    if (!contextResult.isNorboyRelated && contextResult.type !== 'greeting' && contextResult.type !== 'gratitude') {
      logger.warn(`‚ùå Pregunta FUERA DE CONTEXTO: "${message.substring(0, 50)}..."`);
      logger.warn(`   Raz√≥n: ${contextResult.reason}`);

      return {
        type: 'out_of_scope',
        text: contextDetector.MESSAGES.outOfScope,
        shouldEscalate: false,
        context: contextResult
      };
    }

    // 1. Detectar saludos simples (no necesita IA)
    if (isGreeting(normalizedMessage) || contextResult.type === 'greeting') {
      logger.info('üìó Respuesta: Saludo (local)');
      return getGreetingResponse();
    }

    // 2. Detectar comandos de ayuda (no necesita IA)
    if (isHelpCommand(normalizedMessage)) {
      logger.info('üìó Respuesta: Ayuda (local)');
      return getHelpResponse();
    }

    // 2.5 Detectar agradecimientos
    if (contextResult.type === 'gratitude') {
      logger.info('üìó Respuesta: Agradecimiento');
      return 'Con gusto, sumerc√©. Estamos para servirle! üëç';
    }

    // 3. Buscar en base de conocimiento local (para fallback)
    const localAnswer = knowledgeBase.findAnswer(message);

    // 4. NUEVO: Verificar si hay documentos subidos
    const uploadedFiles = knowledgeUploadService.getUploadedFiles();
    const hasUploadedDocs = uploadedFiles.length > 0;

    logger.info(`üìÇ Verificando documentos: ${uploadedFiles.length} encontrados`);

    // 5. Si hay documentos subidos, usar RAG con validaci√≥n estricta
    if (hasUploadedDocs) {
      logger.info(`üìö Hay ${uploadedFiles.length} documento(s) subido(s), usando IA con contexto completo`);
      logger.info(`üìÑ Documentos: ${uploadedFiles.map(f => f.originalName).join(', ')}`);
      logger.info(`üîç openAIAvailable: ${openAIAvailable}`);

      if (openAIAvailable) {
        try {
          logger.info(`üöÄ Llamando a generateWithAI...`);
          const aiResponse = await generateWithAI(userId, message, options);
          logger.info(`‚úÖ generateWithAI retorn√≥ respuesta (tipo: ${typeof aiResponse})`);

          // ‚úÖ CR√çTICO: Verificar si es una respuesta de escalaci√≥n
          if (aiResponse && typeof aiResponse === 'object' && aiResponse.type === 'escalation_no_info') {
            logger.warn('‚ö†Ô∏è generateWithAI retorn√≥ escalaci√≥n, propagando...');
            return aiResponse;
          }

          logger.info('‚úÖ Respuesta: OpenAI con documentos');
          return aiResponse;
        } catch (error) {
          logger.warn('‚ùå OpenAI no disponible con documentos, usando fallback local:', error.message);
          openAIAvailable = false;
          setTimeout(() => { openAIAvailable = true; }, 5 * 60 * 1000);
        }
      } else {
        logger.warn('‚ö†Ô∏è openAIAvailable es FALSE, no se llamar√° a generateWithAI');
      }
    } else {
      logger.info('üì≠ No hay documentos subidos, usando flujo normal');
    }

    // 6. Si NO hay documentos subidos y hay match local, usarlo
    if (!hasUploadedDocs && localAnswer) {
      if (localAnswer.confidence === 'alta' || localAnswer.confidence === 'media') {
        logger.info(`üìó Respuesta: Knowledge Base (${localAnswer.confidence})`);
        return humanizeResponse(localAnswer.answer);
      }
    }

    // 7. Si OpenAI est√° disponible, intentar usarlo para preguntas complejas
    if (openAIAvailable) {
      try {
        const aiResponse = await generateWithAI(userId, message, options);
        logger.info('üìò Respuesta: OpenAI');
        return aiResponse;
      } catch (error) {
        logger.warn('OpenAI no disponible, usando fallback local');
        openAIAvailable = false;

        // Reintentar OpenAI despu√©s de 5 minutos
        setTimeout(() => {
          openAIAvailable = true;
          logger.info('OpenAI habilitado nuevamente');
        }, 5 * 60 * 1000);
      }
    }

    // 8. Fallback: buscar respuesta aproximada en knowledge base
    if (localAnswer && localAnswer.confidence === 'baja') {
      logger.info('üìó Respuesta: Knowledge Base (fallback)');
      return humanizeResponse(localAnswer.answer);
    }

    // ===========================================
    // ‚úÖ CR√çTICO: NO M√ÅS "√öLTIMO INTENTO CON IA"
    // Si llegamos aqu√≠, ESCALAR INMEDIATAMENTE
    // ===========================================
    logger.warn('‚ö†Ô∏è Sin informaci√≥n suficiente - ESCALANDO (NO inventar respuesta)');

    const response = {
      type: 'escalation_no_info',
      text: contextDetector.MESSAGES.noInformation,
      needsHuman: true,
      escalation: {
        reason: 'no_information_in_knowledge_base',
        priority: 'medium',
        message: 'No se encontr√≥ informaci√≥n relevante en documentos'
      }
    };

    // Actualizar √∫ltimo mensaje de la conversaci√≥n
    conversationStateService.updateLastMessage(userId, message);

    return response;

  } catch (error) {
    logger.error('Error en chat service:', error);
    return getErrorResponse();
  }
};

/**
 * Genera respuesta usando IA (Groq/OpenAI)
 *
 * ‚úÖ MEJORADO: Eval√∫a calidad de fragmentos encontrados antes de decidir escalar
 */
const generateWithAI = async (userId, message, options = {}) => {
  // Obtener contexto de la base de conocimiento original
  const baseContext = knowledgeBase.getContext(message, 3);

  // Obtener archivos subidos
  const files = knowledgeUploadService.getUploadedFiles();
  const hasDocuments = files.length > 0;

  let relevantContext = baseContext;
  let searchResults = [];
  let contextQuality = 'none'; // 'high', 'medium', 'low', 'none'

  if (hasDocuments) {
    logger.info(`üìö Procesando ${files.length} documento(s) subido(s)`);

    // ‚úÖ OPTIMIZADO: USAR RAG OPTIMIZADO CON RE-RANKING E H√çBRIDO
    if (USE_EMBEDDINGS) {
      try {
        logger.info('üîç Usando RAG optimizado con re-ranking...');

        // ‚úÖ MEJORADO: Enriquecer query corta con contexto de conversaci√≥n para mejor RAG
        const ragQuery = enrichQueryWithContext(message, userId);

        // Usar el servicio RAG optimizado
        const ragResult = await ragOptimized.findRelevantChunksOptimized(ragQuery, {
          topK: 7,           // M√°s chunks finales
          useCache: true,    // Usar cache
          useHybrid: true,   // B√∫squeda h√≠brida
          useReranking: true // Re-ranking activo
        });

        if (ragResult.chunks.length > 0) {
          // Usar resultados optimizados
          searchResults = ragResult.chunks.map(r => ({
            text: r.text,
            score: Math.round(r.similarity * 100),
            source: r.source || r.sourceId,
            isQA: r.isQA || false,
            question: r.question || null,
            answer: r.answer || null,
            similarity: r.similarity
          }));

          // Calidad determinada por el servicio optimizado (umbrales ajustados)
          contextQuality = ragResult.quality;

          // Log detallado
          logger.info(`üìä Calidad: ${contextQuality.toUpperCase()} (top: ${ragResult.topSimilarity.toFixed(4)}, avg: ${ragResult.avgSimilarity.toFixed(4)})`);
          logger.info(`üéØ Chunks: ${ragResult.totalFound} ‚Üí ${ragResult.finalCount} (con re-ranking)`);

          // ‚úÖ CR√çTICO: Evaluar escalaci√≥n ANTES de continuar
          const escalationEval = ragOptimized.evaluateEscalation(ragResult, message);
          if (escalationEval.shouldEscalate) {
            logger.warn(`‚ö†Ô∏è ESCALACI√ìN REQUERIDA: ${escalationEval.reason}`);
            logger.warn(`   ‚ùå NO se llamar√° a IA - Score insuficiente`);

            return {
              type: 'escalation_no_info',
              text: contextDetector.MESSAGES.lowConfidence,
              needsHuman: true,
              escalation: {
                reason: escalationEval.reason,
                priority: 'medium',
                scores: {
                  topSimilarity: ragResult.topSimilarity,
                  avgSimilarity: ragResult.avgSimilarity,
                  quality: ragResult.quality
                }
              }
            };
          }
        } else {
          logger.info('‚ö†Ô∏è No hay resultados con RAG optimizado, usando b√∫squeda por keywords');
          searchResults = knowledgeUploadService.searchInFiles(message);
        }
      } catch (error) {
        logger.warn(`‚ùå Error en RAG optimizado: ${error.message}`);
        logger.info('üîÑ Usando b√∫squeda por keywords como fallback');
        searchResults = knowledgeUploadService.searchInFiles(message);
      }
    } else {
      // Usar b√∫squeda por keywords (sistema anterior)
      searchResults = knowledgeUploadService.searchInFiles(message);
    }

    if (searchResults.length > 0) {
      // ‚úÖ OPTIMIZADO: Evaluar calidad de los resultados
      const topScore = searchResults[0].score;
      const avgScore = searchResults.reduce((sum, r) => sum + r.score, 0) / searchResults.length;

      // Determinar calidad del contexto basado en scores (si no se hizo con RAG optimizado)
      if (contextQuality === 'none') {
        // Umbrales ajustados para scores de keywords (0-100)
        if (topScore >= 50) {
          contextQuality = 'high';
          logger.info(`‚úÖ Contexto de ALTA calidad detectado (top score: ${topScore})`);
        } else if (topScore >= 30) {
          contextQuality = 'medium';
          logger.info(`üìä Contexto de calidad MEDIA detectado (top score: ${topScore})`);
        } else if (topScore >= 15) {
          contextQuality = 'low';
          logger.info(`‚ö†Ô∏è Contexto de BAJA calidad detectado (top score: ${topScore})`);
        } else {
          contextQuality = 'very_low';
          logger.info(`‚ùå Contexto de MUY BAJA calidad (top score: ${topScore})`);
        }
      }

      // ‚úÖ CR√çTICO: Si calidad es muy baja, ESCALAR INMEDIATAMENTE
      if (contextQuality === 'very_low' || contextQuality === 'none') {
        logger.warn(`‚ö†Ô∏è ESCALACI√ìN AUTOM√ÅTICA: Calidad ${contextQuality} (topScore: ${topScore})`);
        logger.warn(`   ‚ùå NO se llamar√° a IA - Score insuficiente`);

        return {
          type: 'escalation_no_info',
          text: contextDetector.MESSAGES.lowConfidence,
          needsHuman: true,
          escalation: {
            reason: 'very_low_keyword_score',
            priority: 'medium',
            scores: { topScore, avgScore, quality: contextQuality }
          }
        };
      }

      // Usar fragmentos encontrados (m√°s eficiente y preciso)
      logger.info(`üéØ Encontrados ${searchResults.length} fragmentos relevantes (avg score: ${avgScore.toFixed(1)})`);

      // ‚úÖ OPTIMIZADO: Aumentar cantidad de contexto (7 chunks m√°ximo)
      const contextCount = contextQuality === 'high' ? 7 : contextQuality === 'medium' ? 6 : 5;

      // ‚úÖ MEJORADO: Formato m√°s claro para el modelo
      // Si es un chunk Q&A, darle formato estructurado
      const contextFromSearch = searchResults
        .slice(0, contextCount)
        .map(r => {
          // Si el chunk tiene estructura Q&A expl√≠cita, mantenerla clara
          if (r.text.includes('Pregunta:') && r.text.includes('Respuesta:')) {
            return `üìã Pregunta y Respuesta (de: ${r.source}):\n${r.text}`;
          } else {
            // Si es un chunk gen√©rico, indicarlo claramente
            return `üìÑ Informaci√≥n relevante (de: ${r.source}):\n${r.text}`;
          }
        })
        .join('\n\n---\n\n');

      relevantContext = relevantContext
        ? `${relevantContext}\n\n--- Informaci√≥n de documentos ---\n${contextFromSearch}`
        : contextFromSearch;
    } else {
      // ‚úÖ CR√çTICO: Sin coincidencias = ESCALAR INMEDIATAMENTE
      // ‚ùå NO pasar "todo el contenido" a la IA (antes esto causaba invenci√≥n)
      logger.warn('‚ö†Ô∏è Sin coincidencias en documentos - ESCALANDO');
      logger.warn('   ‚ùå NO se pasar√° contenido completo a IA');

      return {
        type: 'escalation_no_info',
        text: contextDetector.MESSAGES.noInformation,
        needsHuman: true,
        escalation: {
          reason: 'no_matches_in_documents',
          priority: 'medium',
          message: 'No se encontraron coincidencias en los documentos disponibles'
        }
      };
    }
  }

  // ‚úÖ NUEVO: Obtener historial de conversaci√≥n del d√≠a para dar contexto a la IA
  const conversationHistory = await getConversationHistory(userId);

  const messages = buildMessages(message, conversationHistory, relevantContext, options, { contextQuality, searchResults });

  // Aumentar tokens cuando hay contexto de documentos
  const maxTokens = hasDocuments ? 250 : 150;

  const response = await aiProvider.chat(messages, {
    maxTokens: maxTokens,
    temperature: 0.7 // Un poco m√°s preciso
  });

  const cleanedResponse = cleanQuestionMarks(response);

  // ===========================================
  // DETECTAR RESPUESTA DE BAJA CONFIANZA
  // ===========================================
  // Si la IA indica que no tiene informaci√≥n, activar escalaci√≥n
  //
  // ‚úÖ IMPORTANTE: Excluir el mensaje de escalaci√≥n del sistema para evitar bucle infinito
  const ESCALATION_MESSAGE_PATTERNS = [
    'comprendo, sumerc√©',
    'el asesor de norboy encargado de este tema le atender√°'
  ];

  // Verificar primero si la respuesta es el mensaje de escalaci√≥n (para evitar bucle)
  const isEscalationMessage = ESCALATION_MESSAGE_PATTERNS.some(pattern =>
    cleanedResponse.toLowerCase().includes(pattern)
  );

  if (isEscalationMessage) {
    logger.warn(`‚ö†Ô∏è La IA respondi√≥ con el mensaje de escalaci√≥n para ${userId}`);
    logger.warn(`   Esto indica que la IA NO encontr√≥ informaci√≥n relevante`);
    logger.warn(`   Respuesta: "${cleanedResponse.substring(0, 100)}..."`);
    logger.warn(`   Calidad del contexto: ${contextQuality}, Fragmentos encontrados: ${searchResults.length}`);
    logger.warn(`   ‚úÖ ESCALANDO DIRECTAMENTE - No se intentar√° recuperaci√≥n`);

    // ‚úÖ CR√çTICO: Escalar directamente sin intentar recuperaci√≥n
    // Si la IA respondi√≥ con el mensaje de escalaci√≥n, no hay raz√≥n para volver a intentar
    return {
      type: 'escalation_no_info',
      text: NO_INFO_MESSAGE,
      needsHuman: true,
      escalation: {
        reason: 'ai_no_information',
        priority: 'medium',
        detectedKeyword: 'escalation_message_response',
        originalResponse: cleanedResponse.substring(0, 200),
        contextQuality: contextQuality,
        fragmentsFound: searchResults.length
      }
    };
  }

  // Patrones de baja confianza (EXCLUYENDO el mensaje de escalaci√≥n del sistema)
  const lowConfidencePatterns = [
    'no tengo informaci√≥n',
    'no cuento con informaci√≥n',
    'no dispongo de informaci√≥n',
    'no se encuentra informaci√≥n',
    'no mencionas',
    'no especificas',
    'lo siento pero no',
    'no tengo informaci√≥n disponible',
    'no cuento con detalles',
    'estamos verificando esa informaci√≥n'
  ];

  const normalizedResponse = cleanedResponse.toLowerCase().trim();
  const hasLowConfidence = lowConfidencePatterns.some(pattern =>
    normalizedResponse.includes(pattern)
  );

  if (hasLowConfidence) {
    logger.warn(`‚ö†Ô∏è IA indica falta de informaci√≥n para ${userId}`);
    logger.warn(`   Respuesta: "${cleanedResponse.substring(0, 100)}..."`);
    logger.warn(`   Patr√≥n detectado: "${lowConfidencePatterns.find(p => normalizedResponse.includes(p))}"`);
    logger.warn(`   Calidad del contexto: ${contextQuality}, Fragmentos encontrados: ${searchResults.length}`);
    logger.warn(`   ‚úÖ ESCALANDO DIRECTAMENTE - No se intentar√° recuperaci√≥n`);

    // ‚úÖ CR√çTICO: Escalar directamente sin intentar recuperaci√≥n
    // La IA ya revis√≥ los fragmentos e indic√≥ que no hay informaci√≥n suficiente
    // No hay raz√≥n para volver a intentar con la IA
    return {
      type: 'escalation_no_info',
      text: NO_INFO_MESSAGE,
      needsHuman: true,
      escalation: {
        reason: 'ai_no_information',
        priority: 'medium',
        detectedKeyword: 'low_confidence_response',
        originalResponse: cleanedResponse.substring(0, 200),
        contextQuality: contextQuality,
        fragmentsFound: searchResults.length
      }
    };
  }

  return cleanedResponse;
};

/**
 * Detecta si es un saludo
 * ‚úÖ MEJORADO: Case-insensitive y m√°s variaciones
 */
const isGreeting = (text) => {
  const normalizedText = text.toLowerCase().trim();

  const greetings = [
    // Formas est√°ndar
    'hola', 'buenos dias', 'buenas tardes', 'buenas noches',
    'buen dia', 'buen dia', 'buenos dias',

    // Informales
    'hey', 'hi', 'hello', 'saludos', 'que tal', 'buenas',

    // Variaciones comunes con errores tipogr√°ficos
    'ola', 'holi', 'holaa', 'holaaa', 'hla', 'hlaa', 'hol',
    'buenas', 'bueno', 'bno', 'bn'
  ];

  // Verificar coincidencias exactas o que comiencen con el saludo
  return greetings.some(g =>
    normalizedText === g ||
    normalizedText.startsWith(g + ' ') ||
    normalizedText.startsWith(g + ',') ||
    normalizedText.startsWith(g + '.') ||
    normalizedText.startsWith(g + '!')
  );
};

/**
 * Detecta si es comando de ayuda
 */
const isHelpCommand = (text) => {
  const helpCommands = ['ayuda', 'help', 'menu', '/ayuda', '/help', '/menu', 'opciones', 'comandos'];
  return helpCommands.includes(text);
};

/**
 * Respuesta de saludo
 */
const getGreetingResponse = () => {
  const greetings = [
    `Hola! üëã Somos el equipo NORBOY. Sumerc√©, en qu√© le podemos ayudar?`,
    `Buen d√≠a! Somos NORBOY. Sumerc√©, qu√© necesita saber?`,
    `Hola! Aqu√≠ el equipo NORBOY üëã En qu√© le podemos servir?`,
    `Saludos! Somos NORBOY. Cu√©ntenos, en qu√© le ayudamos?`
  ];

  return greetings[Math.floor(Math.random() * greetings.length)];
};

/**
 * Respuesta de ayuda/men√∫
 */
const getHelpResponse = () => {
  return `Con gusto le ayudamos! Puede preguntarnos sobre:

‚Ä¢ Delegados y c√≥mo elegirlos
‚Ä¢ La Asamblea General
‚Ä¢ Consejo de Administraci√≥n
‚Ä¢ Junta de Vigilancia
‚Ä¢ El proceso "Elegimos Juntos"

Escr√≠banos su pregunta, estamos para servirle üëç`;
};

/**
 * Mensaje cuando la IA no tiene informaci√≥n suficiente
 */
const NO_INFO_MESSAGE = 'El asesor de NORBOY üë©‚Äçüíº encargado de este tema le atender√° en breve...';

/**
 * ‚úÖ CR√çTICO: FUNCI√ìN ELIMINADA - NO M√ÅS RESPUESTAS INVENTADAS
 *
 * ANTES: Esta funci√≥n llamaba a la IA sin restricciones cuando no hab√≠a info.
 * AHORA: SIEMPRE escalar cuando no hay informaci√≥n suficiente.
 *
 * ‚ùå NUNCA llamar a IA sin contexto de documentos
 * ‚úÖ SIEMPRE escalar a asesor humano
 */
const getGenericResponse = async (originalMessage) => {
  logger.warn(`‚ö†Ô∏è Sin informaci√≥n en base de conocimientos local para: "${originalMessage.substring(0, 50)}..."`);
  logger.warn(`‚ùå NO se llamar√° a IA sin contexto - ESCALANDO INMEDIATAMENTE`);

  // SIEMPRE escalar - NUNCA inventar respuestas
  return {
    type: 'escalation_no_info',
    text: contextDetector.MESSAGES.noInformation,
    needsHuman: true,
    escalation: {
      reason: 'no_knowledge_match',
      priority: 'medium',
      message: 'No se encontr√≥ informaci√≥n en base de conocimientos - Escalaci√≥n autom√°tica'
    }
  };
};

/**
 * Respuesta de error
 */
const getErrorResponse = () => {
  return `Disculpe sumerc√©, tuvimos un problema t√©cnico. Por favor intente de nuevo en unos segundos.`;
};

/**
 * Mensaje de consentimiento (con lista de opciones)
 */
const getConsentMessage = (userId) => {
  // Marcar que se envi√≥ el mensaje de consentimiento
  if (userId) {
    conversationStateService.markConsentSent(userId);
  }

  return {
    type: 'consent',
    text: `üëã ¬°Bienvenido a NORBOY!

Para poder asesorarte mejor,
te solicitamos autorizar el
tratamiento de tus datos personales.

üëâ Con√≥cenos aqu√≠:
https://norboy.coop/

üìÑ Consulta nuestras pol√≠ticas:
üîí Pol√≠tica de Protecci√≥n de Datos Personales:
https://norboy.coop/proteccion-de-datos-personales/
üí¨ Uso de WhatsApp:
https://www.whatsapp.com/legal

‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
‚ö†Ô∏è IMPORTANTE

¬øAceptas las pol√≠ticas de tratamiento de datos personales?

Por favor, digita:

1. Si
2. No`,
    useList: false // No usar lista por ahora, solo texto
  };
};

/**
 * Verifica si el usuario ha dado consentimiento
 */
const hasUserConsent = (userId) => {
  return userConsent.get(userId) === true;
};

/**
 * Registra la respuesta de consentimiento del usuario
 */
const setConsentResponse = (userId, accepted) => {
  userConsent.set(userId, accepted);

  // Sincronizar con conversationStateService
  conversationStateService.updateConsentStatus(userId, accepted ? 'accepted' : 'rejected');

  logger.info(`üìã Usuario ${userId} ${accepted ? 'ACEPT√ì' : 'RECHAZ√ì'} el consentimiento`);
  return accepted;
};

/**
 * Reinicia el contador de interacciones de un usuario
 */
const resetUserInteractions = (userId) => {
  userInteractionCount.set(userId, 0);
  userConsentRequested.delete(userId);
};

/**
 * Obtiene el n√∫mero de interacciones de un usuario
 */
const getUserInteractionCount = (userId) => {
  return userInteractionCount.get(userId) || 0;
};

/**
 * Obtiene el mensaje pendiente de un usuario (para responder despu√©s de aceptar)
 */
const getPendingMessage = (userId) => {
  return pendingMessages.get(userId) || null;
};

/**
 * Limpia el mensaje pendiente de un usuario
 */
const clearPendingMessage = (userId) => {
  pendingMessages.delete(userId);
};

/**
 * Reset completo del estado de un usuario
 * Limpia todas las variables de estado para un usuario espec√≠fico
 *
 * Se llama cuando:
 * - Reset manual desde el dashboard
 * - El ciclo de 60 minutos expira
 *
 * Esto asegura que el pr√≥ximo mensaje del usuario reciba:
 * - Saludo de bienvenida
 * - Mensaje de consentimiento de datos
 */
const resetUserState = (userId) => {
  userInteractionCount.delete(userId);
  userConsent.delete(userId);
  userConsentRequested.delete(userId);
  pendingMessages.delete(userId);

  logger.info(`üîÑ Estado reseteado completamente para ${userId}`);
};

/**
 * Humaniza una respuesta local (mantiene respuestas cortas)
 */
const humanizeResponse = (answer) => {
  const starters = ['', 'Claro! ', 'Con gusto, ', 'Le cuento: ', 'Por supuesto, '];
  const randomStarter = starters[Math.floor(Math.random() * starters.length)];

  const closers = [
    '',
    '\n\nEstamos para servirle, sumerc√© es lo m√°s importante! üòä',
    '',
    '\n\nQu√© m√°s le podemos ayudar?',
    ''
  ];
  const randomCloser = closers[Math.floor(Math.random() * closers.length)];

  return `${randomStarter}${answer}${randomCloser}`;
};

/**
 * Limpia signos de interrogaci√≥n invertidos
 */
const cleanQuestionMarks = (text) => {
  return text.replace(/¬ø/g, '');
};

/**
 * Mensaje cuando se escala a humano
 */
const getEscalationMessage = (escalation) => {
  return {
    type: 'escalation',
    text: `El asesor de NORBOY üë©‚Äçüíº encargado de este tema le atender√° en breve...`,
    needsHuman: true,
    escalation
  };
};

/**
 * Mensaje fuera de horario
 */
const getOutOfHoursMessage = () => {
  const nextOpening = escalationService.getNextOpeningTime();
  const sched = scheduleConfig.getFormattedSchedule();

  return {
    type: 'out_of_hours',
    text: `Sumerc√©, nuestro horario de atenci√≥n es:
üìÖ Lunes a Viernes: ${sched.weekdaysLabel}
üìÖ S√°bados: ${sched.saturdayLabel}
‚ùå Domingos: ${sched.sundayLabel}

Lo atenderemos con gusto:
üìÖ ${nextOpening.formatted}

üåô Buenas noches.`
  };
};

/**
 * Construye mensajes para IA
 *
 * ‚úÖ MEJORADO: Prompt m√°s flexible con fragmentos numerados y scores de relevancia
 * ‚úÖ NUEVO: Ajusta el prompt seg√∫n la calidad del contexto encontrado
 */
const buildMessages = (userMessage, history = [], context = '', options = {}, contextInfo = {}) => {
  const messages = [];
  const { contextQuality = 'none', searchResults = [] } = contextInfo;

  const systemPrompt = options.systemPrompt || config.openai.systemPrompts.default;

  messages.push({
    role: 'system',
    content: systemPrompt
  });

  if (context) {
    // ‚úÖ MEJORADO: Construir prompt con fragmentos numerados y scores
    const promptContext = buildImprovedPrompt(userMessage, searchResults, contextQuality);

    messages.push({
      role: 'system',
      content: promptContext
    });
  } else {
    // Si no hay contexto de documentos, permitir respuestas m√°s generales sobre NORBOY
    messages.push({
      role: 'system',
      content: `üìã BASE DE CONOCIMIENTO:\nNo hay documentos espec√≠ficos cargados.\n\nINSTRUCCIONES:
1. Responde preguntas generales sobre NORBOY (cooperativa, proceso electoral, delegados)
2. Si la pregunta requiere informaci√≥n espec√≠fica (fechas, montos, detalles), di: "Estamos verificando esa informaci√≥n. Un asesor te contestar√° en breve."
3. Si la pregunta es sobre temas completamente ajenos a NORBOY, indica amablemente que un asesor le ayudar√°
4. Responde siempre de manera amable usando "sumerc√©" para dirigirte al usuario

NO respondas sobre temas ajenos a la cooperativa (ciencia, historia, geograf√≠a, clima, etc.).`
    });
  }

  for (const msg of history) {
    messages.push({ role: msg.role, content: msg.content });
  }

  messages.push({ role: 'user', content: userMessage });

  return messages;
};

/**
 * Construye un prompt mejorado con fragmentos numerados y scores
 * ‚úÖ NUEVO: Formato estructurado para mejor comprensi√≥n de la IA
 */
const buildImprovedPrompt = (userMessage, searchResults, contextQuality) => {
  // Calcular score promedio y m√°ximo
  const scores = searchResults.map(r => r.score).filter(s => s !== undefined);
  const topScore = scores.length > 0 ? Math.max(...scores) : 0;

  // Construir fragmentos con numeraci√≥n
  const fragmentsText = searchResults
    .map((result, index) => {
      const scoreInfo = result.score !== undefined ? ` (Relevancia: ${(result.score * 100).toFixed(0)}%)` : '';
      return `
[FRAGMENTO ${index + 1}]${scoreInfo}
${result.text}
---`;
    })
    .join('\n');

  // Instrucciones seg√∫n calidad
  let instructions = '';

  if (contextQuality === 'high' && topScore > 0.6) {
    // Alta confianza
    instructions = `
INSTRUCCIONES:
- La informaci√≥n proporcionada es altamente relevante
- Responde de forma clara y directa usando estos fragmentos
- Cita datos espec√≠ficos (fechas, n√∫meros, lugares) cuando sea apropiado
- Si el documento dice "9 al 14 de febrero" y preguntan "qu√© d√≠a son los votos", RESPONDE con esa fecha`;
  }
  else if (contextQuality === 'medium' || (contextQuality === 'high' && topScore < 0.6)) {
    // Confianza media
    instructions = `
INSTRUCCIONES:
- Usa la informaci√≥n disponible para responder
- Si la informaci√≥n es insuficiente para responder completamente, ind√≠calo
- S√© honesto sobre las limitaciones de los fragmentos proporcionados
- Si hace falta informaci√≥n crucial, sugiere contactar a NORBOY`;
  }
  else {
    // Baja confianza
    instructions = `
INSTRUCCIONES:
- Los fragmentos disponibles no parecen responder directamente la pregunta
- Genera una respuesta cort√©s indicando que no tienes esa informaci√≥n espec√≠fica
- Sugiere contactar directamente a NORBOY para esta consulta
- Formato sugerido: "Sumerc√©, no encuentro informaci√≥n espec√≠fica sobre [tema] en los documentos disponibles. Le recomiendo contactar a NORBOY en..."`;
  }

  return `
PREGUNTA DEL USUARIO:
"${userMessage}"

FRAGMENTOS RECUPERADOS DE LOS DOCUMENTOS:
${fragmentsText}

${instructions}

NOTA IMPORTANTE: Si los fragmentos contienen caracteres como "√É¬©", "√É¬≥", "√É¬±", interpr√©talos como caracteres especiales espa√±oles (√©, √≥, √±) y comprende el contexto.

RESPUESTA:`;
};

/**
 * Obtiene el historial de conversaci√≥n del d√≠a actual
 *
 * @param {string} userId - ID del usuario
 * @returns {Array} Historial de mensajes del d√≠a en formato OpenAI
 */
const getConversationHistory = async (userId) => {
  try {
    // Obtener el servicio de estado de conversaci√≥n
    const conversationStateService = require('./conversation-state.service');
    const conversation = conversationStateService.getConversation(userId);

    if (!conversation || !conversation.messages || conversation.messages.length === 0) {
      return [];
    }

    // Obtener mensajes de hoy (√∫ltimas 24 horas)
    const now = Date.now();
    const oneDayMs = 24 * 60 * 60 * 1000;
    const todayStart = now - oneDayMs;

    // Filtrar mensajes de hoy y convertirlos al formato de OpenAI
    const todayMessages = conversation.messages
      .filter(msg => msg.timestamp >= todayStart)
      .map(msg => {
        // Mapear sender a role
        let role = 'user';
        if (msg.sender === 'bot' || msg.sender === 'admin') {
          role = 'assistant';
        }

        return {
          role: role,
          content: msg.message
        };
      });

    logger.debug(`üìú Historial cargado para ${userId}: ${todayMessages.length} mensajes de hoy`);

    return todayMessages;
  } catch (error) {
    logger.error(`Error obteniendo historial de conversaci√≥n para ${userId}:`, error);
    return [];
  }
};

/**
 * Obtiene informaci√≥n por categor√≠a
 */
const getInfoByCategory = (category) => {
  const items = knowledgeBase.getByCategory(category);
  if (items.length === 0) return null;
  return items.map(item => `‚Ä¢ ${item.question}\n  ${item.answer}`).join('\n\n');
};

/**
 * Lista categor√≠as disponibles
 */
const getAvailableCategories = () => {
  return knowledgeBase.getCategories();
};

module.exports = {
  generateTextResponse,
  getConversationHistory,
  buildMessages,
  getInfoByCategory,
  getAvailableCategories,
  cleanQuestionMarks,
  hasUserConsent,
  setConsentResponse,
  resetUserInteractions,
  getUserInteractionCount,
  getPendingMessage,
  clearPendingMessage,
  resetUserState,
  getEscalationMessage,
  getOutOfHoursMessage,
  NO_INFO_MESSAGE  // Exportar para uso en otros m√≥dulos
};
