/**
 * ===========================================
 * SERVICIO DE CHAT H√çBRIDO - NORBOY
 * ===========================================
 *
 * Sistema inteligente que decide:
 * 1. Si hay match en la base de conocimiento local ‚Üí responde sin IA
 * 2. Si la pregunta es compleja o no hay match ‚Üí usa OpenAI
 * 3. Si OpenAI falla ‚Üí fallback a base de conocimiento
 */

const logger = require('../utils/logger');
const config = require('../config');
const aiProvider = require('../providers/ai');
const knowledgeBase = require('../knowledge');
const knowledgeUploadService = require('./knowledge-upload.service');
const conversationStateService = require('./conversation-state.service');
const escalationService = require('./escalation.service');
const embeddingsService = require('./embeddings.service'); // ‚úÖ NUEVO: B√∫squeda vectorial
const ragOptimized = require('./rag-optimized.service'); // ‚úÖ NUEVO: RAG Optimizado
const contextDetector = require('./context-detector.service'); // ‚úÖ CR√çTICO: Detector de contexto

// Inicializar base de conocimiento
knowledgeBase.initialize();

// Flag para saber si OpenAI est√° disponible
let openAIAvailable = true;

// ‚úÖ NUEVO: Flag para habilitar/deshabilitar b√∫squeda vectorial
const USE_EMBEDDINGS = process.env.USE_EMBEDDINGS !== 'false'; // Por defecto: true

// ===========================================
// SEGUIMIENTO DE CONSENTIMIENTO DE USUARIOS
// ===========================================
const userInteractionCount = new Map(); // userId ‚Üí n√∫mero de interacciones
const userConsent = new Map(); // userId ‚Üí boolean (acept√≥ o no)
const userConsentRequested = new Map(); // userId ‚Üí boolean (ya se mostr√≥ mensaje)
const pendingMessages = new Map(); // userId ‚Üí mensaje pendiente (para responder despu√©s de aceptar)

/**
 * Genera una respuesta de chat (H√çBRIDO)
 */
const generateTextResponse = async (userId, message, options = {}) => {
  try {
    const normalizedMessage = message.toLowerCase().trim();
    logger.debug(`Procesando: "${message.substring(0, 50)}..."}`);

    // ===========================================
    // VERIFICACI√ìN DE CICLO DE 60 MINUTOS
    // ===========================================
    const wasReset = conversationStateService.checkAndUpdateCycle(userId);

    if (wasReset) {
      // Si el ciclo expir√≥, resetear TODAS las variables de consentimiento
      logger.info(`üîÑ Ciclo reseteado para ${userId}, limpiando TODO el estado`);
      resetUserState(userId);

      // Indicar que se debe enviar bienvenida y consentimiento nuevamente
      // Esto har√° que en la siguiente interacci√≥n se vuelva a mostrar el flujo completo
    }

    // ===========================================
    // SISTEMA DE CONSENTIMIENTO
    // ===========================================

    // Incrementar contador de interacciones (solo si no es skipConsent)
    const currentCount = options.skipConsent
      ? (userInteractionCount.get(userId) || 0)
      : (userInteractionCount.get(userId) || 0) + 1;

    if (!options.skipConsent) {
      userInteractionCount.set(userId, currentCount);
      conversationStateService.incrementInteractionCount(userId);
      logger.info(`üí¨ Usuario ${userId}: Interacci√≥n #${currentCount}`);
    }

    // ===========================================
    // IMPORTANTE: NO evaluar escalaci√≥n aqu√≠
    // La escalaci√≥n se maneja en messageProcessor
    // Aqu√≠ solo intentar responder
    // ===========================================

    // Si es la SEGUNDA interacci√≥n y no ha respondido consentimiento, mostrar mensaje
    if (currentCount === 2 && !userConsent.has(userId) && !userConsentRequested.get(userId) && !options.skipConsent) {
      logger.info('üìã Segunda interacci√≥n, solicitando consentimiento');
      userConsentRequested.set(userId, true);

      // Guardar el mensaje para responderlo despu√©s de que acepte
      pendingMessages.set(userId, message);
      logger.info(`üìù Mensaje pendiente guardado: "${message.substring(0, 50)}..."`);

      return getConsentMessage(userId);
    }

    // Si NO ha aceptado el consentimiento, no responder
    if (userConsent.get(userId) === false && !options.skipConsent) {
      logger.info('üö´ Usuario rechaz√≥ consentimiento, no responde');
      return null; // No responder
    }

    // Si a√∫n no ha aceptado (esperando respuesta a botones), no procesar
    if (currentCount > 2 && !userConsent.has(userId) && !options.skipConsent) {
      logger.info('‚è≥ Esperando respuesta de consentimiento');
      return null;
    }

    // ===========================================
    // ‚úÖ CR√çTICO: DETECTAR CONTEXTO ANTES DE TODO
    // ===========================================
    const contextResult = contextDetector.detectContext(message);

    logger.info(`üîç Contexto detectado: ${contextResult.type} (NORBOY: ${contextResult.isNorboyRelated})`);

    // Si NO es sobre NORBOY ‚Üí Mensaje restrictivo inmediato
    if (!contextResult.isNorboyRelated && contextResult.type !== 'greeting' && contextResult.type !== 'gratitude') {
      logger.warn(`‚ùå Pregunta FUERA DE CONTEXTO: "${message.substring(0, 50)}..."`);
      logger.warn(`   Raz√≥n: ${contextResult.reason}`);

      return {
        type: 'out_of_scope',
        text: contextDetector.MESSAGES.outOfScope,
        shouldEscalate: false,
        context: contextResult
      };
    }

    // 1. Detectar saludos simples (no necesita IA)
    if (isGreeting(normalizedMessage) || contextResult.type === 'greeting') {
      logger.info('üìó Respuesta: Saludo (local)');
      return getGreetingResponse();
    }

    // 2. Detectar comandos de ayuda (no necesita IA)
    if (isHelpCommand(normalizedMessage)) {
      logger.info('üìó Respuesta: Ayuda (local)');
      return getHelpResponse();
    }

    // 2.5 Detectar agradecimientos
    if (contextResult.type === 'gratitude') {
      logger.info('üìó Respuesta: Agradecimiento');
      return 'Con gusto, sumerc√©. Estamos para servirle! üëç';
    }

    // 3. Buscar en base de conocimiento local (para fallback)
    const localAnswer = knowledgeBase.findAnswer(message);

    // 4. NUEVO: Verificar si hay documentos subidos
    const uploadedFiles = knowledgeUploadService.getUploadedFiles();
    const hasUploadedDocs = uploadedFiles.length > 0;

    logger.info(`üìÇ Verificando documentos: ${uploadedFiles.length} encontrados`);

    // 5. Si hay documentos subidos, usar RAG con validaci√≥n estricta
    if (hasUploadedDocs) {
      logger.info(`üìö Hay ${uploadedFiles.length} documento(s) subido(s), usando IA con contexto completo`);
      logger.info(`üìÑ Documentos: ${uploadedFiles.map(f => f.originalName).join(', ')}`);
      if (openAIAvailable) {
        try {
          const aiResponse = await generateWithAI(userId, message, options);
          logger.info('‚úÖ Respuesta: OpenAI con documentos');
          return aiResponse;
        } catch (error) {
          logger.warn('‚ùå OpenAI no disponible con documentos, usando fallback local:', error.message);
          openAIAvailable = false;
          setTimeout(() => { openAIAvailable = true; }, 5 * 60 * 1000);
        }
      }
    } else {
      logger.info('üì≠ No hay documentos subidos, usando flujo normal');
    }

    // 6. Si NO hay documentos subidos y hay match local, usarlo
    if (!hasUploadedDocs && localAnswer) {
      if (localAnswer.confidence === 'alta' || localAnswer.confidence === 'media') {
        logger.info(`üìó Respuesta: Knowledge Base (${localAnswer.confidence})`);
        return humanizeResponse(localAnswer.answer);
      }
    }

    // 7. Si OpenAI est√° disponible, intentar usarlo para preguntas complejas
    if (openAIAvailable) {
      try {
        const aiResponse = await generateWithAI(userId, message, options);
        logger.info('üìò Respuesta: OpenAI');
        return aiResponse;
      } catch (error) {
        logger.warn('OpenAI no disponible, usando fallback local');
        openAIAvailable = false;

        // Reintentar OpenAI despu√©s de 5 minutos
        setTimeout(() => {
          openAIAvailable = true;
          logger.info('OpenAI habilitado nuevamente');
        }, 5 * 60 * 1000);
      }
    }

    // 8. Fallback: buscar respuesta aproximada en knowledge base
    if (localAnswer && localAnswer.confidence === 'baja') {
      logger.info('üìó Respuesta: Knowledge Base (fallback)');
      return humanizeResponse(localAnswer.answer);
    }

    // ===========================================
    // ‚úÖ CR√çTICO: NO M√ÅS "√öLTIMO INTENTO CON IA"
    // Si llegamos aqu√≠, ESCALAR INMEDIATAMENTE
    // ===========================================
    logger.warn('‚ö†Ô∏è Sin informaci√≥n suficiente - ESCALANDO (NO inventar respuesta)');

    const response = {
      type: 'escalation_no_info',
      text: contextDetector.MESSAGES.noInformation,
      needsHuman: true,
      escalation: {
        reason: 'no_information_in_knowledge_base',
        priority: 'medium',
        message: 'No se encontr√≥ informaci√≥n relevante en documentos'
      }
    };

    // Actualizar √∫ltimo mensaje de la conversaci√≥n
    conversationStateService.updateLastMessage(userId, message);

    return response;

  } catch (error) {
    logger.error('Error en chat service:', error);
    return getErrorResponse();
  }
};

/**
 * Genera respuesta usando IA (Groq/OpenAI)
 *
 * ‚úÖ MEJORADO: Eval√∫a calidad de fragmentos encontrados antes de decidir escalar
 */
const generateWithAI = async (userId, message, options = {}) => {
  // Obtener contexto de la base de conocimiento original
  const baseContext = knowledgeBase.getContext(message, 3);

  // Obtener archivos subidos
  const files = knowledgeUploadService.getUploadedFiles();
  const hasDocuments = files.length > 0;

  let relevantContext = baseContext;
  let searchResults = [];
  let contextQuality = 'none'; // 'high', 'medium', 'low', 'none'

  if (hasDocuments) {
    logger.info(`üìö Procesando ${files.length} documento(s) subido(s)`);

    // ‚úÖ OPTIMIZADO: USAR RAG OPTIMIZADO CON RE-RANKING E H√çBRIDO
    if (USE_EMBEDDINGS) {
      try {
        logger.info('üîç Usando RAG optimizado con re-ranking...');

        // Usar el servicio RAG optimizado
        const ragResult = await ragOptimized.findRelevantChunksOptimized(message, {
          topK: 7,           // M√°s chunks finales
          useCache: true,    // Usar cache
          useHybrid: true,   // B√∫squeda h√≠brida
          useReranking: true // Re-ranking activo
        });

        if (ragResult.chunks.length > 0) {
          // Usar resultados optimizados
          searchResults = ragResult.chunks.map(r => ({
            text: r.text,
            score: Math.round(r.similarity * 100),
            source: r.source || r.sourceId,
            isQA: r.isQA || false,
            question: r.question || null,
            answer: r.answer || null,
            similarity: r.similarity
          }));

          // Calidad determinada por el servicio optimizado (umbrales ajustados)
          contextQuality = ragResult.quality;

          // Log detallado
          logger.info(`üìä Calidad: ${contextQuality.toUpperCase()} (top: ${ragResult.topSimilarity.toFixed(4)}, avg: ${ragResult.avgSimilarity.toFixed(4)})`);
          logger.info(`üéØ Chunks: ${ragResult.totalFound} ‚Üí ${ragResult.finalCount} (con re-ranking)`);

          // ‚úÖ CR√çTICO: Evaluar escalaci√≥n ANTES de continuar
          const escalationEval = ragOptimized.evaluateEscalation(ragResult, message);
          if (escalationEval.shouldEscalate) {
            logger.warn(`‚ö†Ô∏è ESCALACI√ìN REQUERIDA: ${escalationEval.reason}`);
            logger.warn(`   ‚ùå NO se llamar√° a IA - Score insuficiente`);

            return {
              type: 'escalation_no_info',
              text: contextDetector.MESSAGES.lowConfidence,
              needsHuman: true,
              escalation: {
                reason: escalationEval.reason,
                priority: 'medium',
                scores: {
                  topSimilarity: ragResult.topSimilarity,
                  avgSimilarity: ragResult.avgSimilarity,
                  quality: ragResult.quality
                }
              }
            };
          }
        } else {
          logger.info('‚ö†Ô∏è No hay resultados con RAG optimizado, usando b√∫squeda por keywords');
          searchResults = knowledgeUploadService.searchInFiles(message);
        }
      } catch (error) {
        logger.warn(`‚ùå Error en RAG optimizado: ${error.message}`);
        logger.info('üîÑ Usando b√∫squeda por keywords como fallback');
        searchResults = knowledgeUploadService.searchInFiles(message);
      }
    } else {
      // Usar b√∫squeda por keywords (sistema anterior)
      searchResults = knowledgeUploadService.searchInFiles(message);
    }

    if (searchResults.length > 0) {
      // ‚úÖ OPTIMIZADO: Evaluar calidad de los resultados
      const topScore = searchResults[0].score;
      const avgScore = searchResults.reduce((sum, r) => sum + r.score, 0) / searchResults.length;

      // Determinar calidad del contexto basado en scores (si no se hizo con RAG optimizado)
      if (contextQuality === 'none') {
        // Umbrales ajustados para scores de keywords (0-100)
        if (topScore >= 50) {
          contextQuality = 'high';
          logger.info(`‚úÖ Contexto de ALTA calidad detectado (top score: ${topScore})`);
        } else if (topScore >= 30) {
          contextQuality = 'medium';
          logger.info(`üìä Contexto de calidad MEDIA detectado (top score: ${topScore})`);
        } else if (topScore >= 15) {
          contextQuality = 'low';
          logger.info(`‚ö†Ô∏è Contexto de BAJA calidad detectado (top score: ${topScore})`);
        } else {
          contextQuality = 'very_low';
          logger.info(`‚ùå Contexto de MUY BAJA calidad (top score: ${topScore})`);
        }
      }

      // ‚úÖ CR√çTICO: Si calidad es muy baja, ESCALAR INMEDIATAMENTE
      if (contextQuality === 'very_low' || contextQuality === 'none') {
        logger.warn(`‚ö†Ô∏è ESCALACI√ìN AUTOM√ÅTICA: Calidad ${contextQuality} (topScore: ${topScore})`);
        logger.warn(`   ‚ùå NO se llamar√° a IA - Score insuficiente`);

        return {
          type: 'escalation_no_info',
          text: contextDetector.MESSAGES.lowConfidence,
          needsHuman: true,
          escalation: {
            reason: 'very_low_keyword_score',
            priority: 'medium',
            scores: { topScore, avgScore, quality: contextQuality }
          }
        };
      }

      // Usar fragmentos encontrados (m√°s eficiente y preciso)
      logger.info(`üéØ Encontrados ${searchResults.length} fragmentos relevantes (avg score: ${avgScore.toFixed(1)})`);

      // ‚úÖ OPTIMIZADO: Aumentar cantidad de contexto (7 chunks m√°ximo)
      const contextCount = contextQuality === 'high' ? 7 : contextQuality === 'medium' ? 6 : 5;

      // ‚úÖ MEJORADO: Formato m√°s claro para el modelo
      // Si es un chunk Q&A, darle formato estructurado
      const contextFromSearch = searchResults
        .slice(0, contextCount)
        .map(r => {
          // Si el chunk tiene estructura Q&A expl√≠cita, mantenerla clara
          if (r.text.includes('Pregunta:') && r.text.includes('Respuesta:')) {
            return `üìã Pregunta y Respuesta (de: ${r.source}):\n${r.text}`;
          } else {
            // Si es un chunk gen√©rico, indicarlo claramente
            return `üìÑ Informaci√≥n relevante (de: ${r.source}):\n${r.text}`;
          }
        })
        .join('\n\n---\n\n');

      relevantContext = relevantContext
        ? `${relevantContext}\n\n--- Informaci√≥n de documentos ---\n${contextFromSearch}`
        : contextFromSearch;
    } else {
      // ‚úÖ CR√çTICO: Sin coincidencias = ESCALAR INMEDIATAMENTE
      // ‚ùå NO pasar "todo el contenido" a la IA (antes esto causaba invenci√≥n)
      logger.warn('‚ö†Ô∏è Sin coincidencias en documentos - ESCALANDO');
      logger.warn('   ‚ùå NO se pasar√° contenido completo a IA');

      return {
        type: 'escalation_no_info',
        text: contextDetector.MESSAGES.noInformation,
        needsHuman: true,
        escalation: {
          reason: 'no_matches_in_documents',
          priority: 'medium',
          message: 'No se encontraron coincidencias en los documentos disponibles'
        }
      };
    }
  }

  // ‚úÖ NUEVO: Obtener historial de conversaci√≥n del d√≠a para dar contexto a la IA
  const conversationHistory = await getConversationHistory(userId);

  const messages = buildMessages(message, conversationHistory, relevantContext, options, { contextQuality, searchResults });

  // Aumentar tokens cuando hay contexto de documentos
  const maxTokens = hasDocuments ? 400 : 150;

  const response = await aiProvider.chat(messages, {
    maxTokens: maxTokens,
    temperature: 0.7 // Un poco m√°s preciso
  });

  const cleanedResponse = cleanQuestionMarks(response);

  // ===========================================
  // DETECTAR RESPUESTA DE BAJA CONFIANZA
  // ===========================================
  // Si la IA indica que no tiene informaci√≥n, activar escalaci√≥n
  //
  // ‚úÖ IMPORTANTE: Excluir el mensaje de escalaci√≥n del sistema para evitar bucle infinito
  const ESCALATION_MESSAGE_PATTERNS = [
    'comprendo, sumerc√©',
    'el asesor de norboy encargado de este tema le atender√°'
  ];

  // Verificar primero si la respuesta es el mensaje de escalaci√≥n (para evitar bucle)
  const isEscalationMessage = ESCALATION_MESSAGE_PATTERNS.some(pattern =>
    cleanedResponse.toLowerCase().includes(pattern)
  );

  if (isEscalationMessage) {
    logger.warn(`‚ö†Ô∏è La IA respondi√≥ con el mensaje de escalaci√≥n para ${userId}`);
    logger.warn(`   Esto indica que la IA NO encontr√≥ informaci√≥n relevante`);
    logger.warn(`   Respuesta: "${cleanedResponse.substring(0, 100)}..."`);
    logger.warn(`   Calidad del contexto: ${contextQuality}, Fragmentos encontrados: ${searchResults.length}`);

    // ‚úÖ NUEVO: Si la calidad del contexto es alta o media, intentar respuesta alternativa
    if (contextQuality === 'high' || contextQuality === 'medium') {
      logger.info(`üîÑ Intentando respuesta alternativa con contexto de calidad ${contextQuality.toUpperCase()}`);

      // Generar respuesta usando el mejor fragmento encontrado
      const topFragment = searchResults[0].text;
      const fallbackResponse = `Seg√∫n la informaci√≥n disponible sobre el proceso electoral:\n\n${topFragment.substring(0, 300)}...\n\nPara m√°s detalles espec√≠ficos, un asesor puede atenderte.`;

      logger.info(`‚úÖ Respuesta alternativa generada usando fragmento top`);
      return fallbackResponse;
    }

    // Retornar el mensaje de escalaci√≥n directamente
    return {
      type: 'escalation_no_info',
      text: NO_INFO_MESSAGE,
      needsHuman: true,
      escalation: {
        reason: 'ai_no_information',
        priority: 'medium',
        detectedKeyword: 'escalation_message_response',
        originalResponse: cleanedResponse.substring(0, 200),
        contextQuality: contextQuality,
        fragmentsFound: searchResults.length
      }
    };
  }

  // Patrones de baja confianza (EXCLUYENDO el mensaje de escalaci√≥n del sistema)
  const lowConfidencePatterns = [
    'no tengo informaci√≥n',
    'no cuento con informaci√≥n',
    'no dispongo de informaci√≥n',
    'no se encuentra informaci√≥n',
    'no mencionas',
    'no especificas',
    'lo siento pero no',
    'no tengo informaci√≥n disponible',
    'no cuento con detalles',
    'estamos verificando esa informaci√≥n'
  ];

  const normalizedResponse = cleanedResponse.toLowerCase().trim();
  const hasLowConfidence = lowConfidencePatterns.some(pattern =>
    normalizedResponse.includes(pattern)
  );

  if (hasLowConfidence) {
    logger.warn(`‚ö†Ô∏è IA indica falta de informaci√≥n para ${userId}`);
    logger.warn(`   Respuesta: "${cleanedResponse.substring(0, 100)}..."`);
    logger.warn(`   Patr√≥n detectado: "${lowConfidencePatterns.find(p => normalizedResponse.includes(p))}"`);
    logger.warn(`   Calidad del contexto: ${contextQuality}, Fragmentos encontrados: ${searchResults.length}`);

    // ‚úÖ NUEVO: Si la calidad del contexto es buena, intentar con el mejor fragmento
    if (contextQuality === 'high' || (contextQuality === 'medium' && searchResults.length >= 3)) {
      logger.info(`üîÑ Recuperando: usando mejor fragmento encontrado (score: ${searchResults[0].score})`);

      const topFragment = searchResults[0].text;
      const fallbackResponse = `${topFragment.substring(0, 500)}...\n\nSi necesitas m√°s detalles, un asesor puede ayudarte.`;

      return fallbackResponse;
    }

    // Retornar objeto especial de escalaci√≥n
    return {
      type: 'escalation_no_info',
      text: NO_INFO_MESSAGE,
      needsHuman: true,
      escalation: {
        reason: 'ai_no_information',
        priority: 'medium',
        detectedKeyword: 'low_confidence_response',
        originalResponse: cleanedResponse.substring(0, 200),
        contextQuality: contextQuality,
        fragmentsFound: searchResults.length
      }
    };
  }

  return cleanedResponse;
};

/**
 * Detecta si es un saludo
 */
const isGreeting = (text) => {
  const greetings = [
    'hola', 'buenos dias', 'buenas tardes', 'buenas noches',
    'hey', 'hi', 'hello', 'saludos', 'que tal', 'buenas',
    'ola', 'holi', 'holaa', 'holaaa'
  ];
  return greetings.some(g => text === g || text.startsWith(g + ' ') || text.startsWith(g + ','));
};

/**
 * Detecta si es comando de ayuda
 */
const isHelpCommand = (text) => {
  const helpCommands = ['ayuda', 'help', 'menu', '/ayuda', '/help', '/menu', 'opciones', 'comandos'];
  return helpCommands.includes(text);
};

/**
 * Respuesta de saludo
 */
const getGreetingResponse = () => {
  const greetings = [
    `Hola! üëã Somos el equipo NORBOY. Sumerc√©, en qu√© le podemos ayudar?`,
    `Buen d√≠a! Somos NORBOY. Sumerc√©, qu√© necesita saber?`,
    `Hola! Aqu√≠ el equipo NORBOY üëã En qu√© le podemos servir?`,
    `Saludos! Somos NORBOY. Cu√©ntenos, en qu√© le ayudamos?`
  ];

  return greetings[Math.floor(Math.random() * greetings.length)];
};

/**
 * Respuesta de ayuda/men√∫
 */
const getHelpResponse = () => {
  return `Con gusto le ayudamos! Puede preguntarnos sobre:

‚Ä¢ Delegados y c√≥mo elegirlos
‚Ä¢ La Asamblea General
‚Ä¢ Consejo de Administraci√≥n
‚Ä¢ Junta de Vigilancia
‚Ä¢ El proceso "Elegimos Juntos"

Escr√≠banos su pregunta, estamos para servirle üëç`;
};

/**
 * Mensaje cuando la IA no tiene informaci√≥n suficiente
 */
const NO_INFO_MESSAGE = 'Comprendo, sumerc√©. üë©‚Äçüíº\n\nEl asesor de NORBOY encargado de este tema le atender√° en breve...';

/**
 * ‚úÖ CR√çTICO: FUNCI√ìN ELIMINADA - NO M√ÅS RESPUESTAS INVENTADAS
 *
 * ANTES: Esta funci√≥n llamaba a la IA sin restricciones cuando no hab√≠a info.
 * AHORA: SIEMPRE escalar cuando no hay informaci√≥n suficiente.
 *
 * ‚ùå NUNCA llamar a IA sin contexto de documentos
 * ‚úÖ SIEMPRE escalar a asesor humano
 */
const getGenericResponse = async (originalMessage) => {
  logger.warn(`‚ö†Ô∏è Sin informaci√≥n en base de conocimientos local para: "${originalMessage.substring(0, 50)}..."`);
  logger.warn(`‚ùå NO se llamar√° a IA sin contexto - ESCALANDO INMEDIATAMENTE`);

  // SIEMPRE escalar - NUNCA inventar respuestas
  return {
    type: 'escalation_no_info',
    text: contextDetector.MESSAGES.noInformation,
    needsHuman: true,
    escalation: {
      reason: 'no_knowledge_match',
      priority: 'medium',
      message: 'No se encontr√≥ informaci√≥n en base de conocimientos - Escalaci√≥n autom√°tica'
    }
  };
};

/**
 * Respuesta de error
 */
const getErrorResponse = () => {
  return `Disculpe sumerc√©, tuvimos un problema t√©cnico. Por favor intente de nuevo en unos segundos.`;
};

/**
 * Mensaje de consentimiento (con lista de opciones)
 */
const getConsentMessage = (userId) => {
  // Marcar que se envi√≥ el mensaje de consentimiento
  if (userId) {
    conversationStateService.markConsentSent(userId);
  }

  return {
    type: 'consent',
    text: `üëã ¬°Bienvenido a NORBOY!

Para poder asesorarte mejor,
te solicitamos autorizar el
tratamiento de tus datos personales.

üëâ Con√≥cenos aqu√≠:
https://norboy.coop/

üìÑ Consulta nuestras pol√≠ticas:
üîí Pol√≠tica de Protecci√≥n de Datos Personales:
https://norboy.coop/proteccion-de-datos-personales/
üí¨ Uso de WhatsApp:
https://www.whatsapp.com/legal

‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
‚ö†Ô∏è IMPORTANTE

¬øAceptas las pol√≠ticas de tratamiento de datos personales?

Por favor, digita:

1. Si
2. No`,
    useList: false // No usar lista por ahora, solo texto
  };
};

/**
 * Verifica si el usuario ha dado consentimiento
 */
const hasUserConsent = (userId) => {
  return userConsent.get(userId) === true;
};

/**
 * Registra la respuesta de consentimiento del usuario
 */
const setConsentResponse = (userId, accepted) => {
  userConsent.set(userId, accepted);

  // Sincronizar con conversationStateService
  conversationStateService.updateConsentStatus(userId, accepted ? 'accepted' : 'rejected');

  logger.info(`üìã Usuario ${userId} ${accepted ? 'ACEPT√ì' : 'RECHAZ√ì'} el consentimiento`);
  return accepted;
};

/**
 * Reinicia el contador de interacciones de un usuario
 */
const resetUserInteractions = (userId) => {
  userInteractionCount.set(userId, 0);
  userConsentRequested.delete(userId);
};

/**
 * Obtiene el n√∫mero de interacciones de un usuario
 */
const getUserInteractionCount = (userId) => {
  return userInteractionCount.get(userId) || 0;
};

/**
 * Obtiene el mensaje pendiente de un usuario (para responder despu√©s de aceptar)
 */
const getPendingMessage = (userId) => {
  return pendingMessages.get(userId) || null;
};

/**
 * Limpia el mensaje pendiente de un usuario
 */
const clearPendingMessage = (userId) => {
  pendingMessages.delete(userId);
};

/**
 * Reset completo del estado de un usuario
 * Limpia todas las variables de estado para un usuario espec√≠fico
 *
 * Se llama cuando:
 * - Reset manual desde el dashboard
 * - El ciclo de 60 minutos expira
 *
 * Esto asegura que el pr√≥ximo mensaje del usuario reciba:
 * - Saludo de bienvenida
 * - Mensaje de consentimiento de datos
 */
const resetUserState = (userId) => {
  userInteractionCount.delete(userId);
  userConsent.delete(userId);
  userConsentRequested.delete(userId);
  pendingMessages.delete(userId);

  logger.info(`üîÑ Estado reseteado completamente para ${userId}`);
};

/**
 * Humaniza una respuesta local (mantiene respuestas cortas)
 */
const humanizeResponse = (answer) => {
  const starters = ['', 'Claro! ', 'Con gusto, ', 'Le cuento: ', 'Por supuesto, '];
  const randomStarter = starters[Math.floor(Math.random() * starters.length)];

  const closers = [
    '',
    '\n\nEstamos para servirle, sumerc√© es lo m√°s importante! üòä',
    '',
    '\n\nQu√© m√°s le podemos ayudar?',
    ''
  ];
  const randomCloser = closers[Math.floor(Math.random() * closers.length)];

  return `${randomStarter}${answer}${randomCloser}`;
};

/**
 * Limpia signos de interrogaci√≥n invertidos
 */
const cleanQuestionMarks = (text) => {
  return text.replace(/¬ø/g, '');
};

/**
 * Mensaje cuando se escala a humano
 */
const getEscalationMessage = (escalation) => {
  return {
    type: 'escalation',
    text: `Comprendo, sumerc√©. üë©‚Äçüíº

El asesor de NORBOY encargado de este tema le atender√° en breve...`,
    needsHuman: true,
    escalation
  };
};

/**
 * Mensaje fuera de horario
 */
const getOutOfHoursMessage = () => {
  const nextOpening = escalationService.getNextOpeningTime();

  return {
    type: 'out_of_hours',
    text: `Sumerc√©, nuestro horario de atenci√≥n es:
üìÖ Lunes a Viernes: 8:00 AM - 4:30 PM
üìÖ S√°bados: 9:00 AM - 12:00 PM
‚ùå Domingos: Cerrado

Lo atenderemos con gusto:
üìÖ ${nextOpening.formatted}

üåô Buenas noches.`
  };
};

/**
 * Construye mensajes para IA
 *
 * ‚úÖ MEJORADO: Prompt m√°s flexible que permite respuestas inteligentes
 * ‚úÖ NUEVO: Ajusta el prompt seg√∫n la calidad del contexto encontrado
 */
const buildMessages = (userMessage, history = [], context = '', options = {}, contextInfo = {}) => {
  const messages = [];
  const { contextQuality = 'none', searchResults = [] } = contextInfo;

  const systemPrompt = options.systemPrompt || config.openai.systemPrompts.default;

  messages.push({
    role: 'system',
    content: systemPrompt
  });

  if (context) {
    // ‚úÖ OPTIMIZADO: Prompt ajustado din√°micamente seg√∫n calidad del contexto
    // Usar formateo del RAG optimizado si est√° disponible
    let promptContext = '';

    // Alta y media calidad: confiar m√°s en los documentos
    if (contextQuality === 'high' || contextQuality === 'medium') {
      // Contexto de buena calidad: ser m√°s exigente usando la informaci√≥n
      promptContext = `üìö INFORMACI√ìN DE DOCUMENTOS (CALIDAD: ${contextQuality.toUpperCase()}):
Se encontraron ${searchResults.length} fragmentos relevantes en los documentos.

${context}

INSTRUCCIONES OBLIGATORIAS (contexto de calidad ${contextQuality.toUpperCase()}):
1. ‚úÖ DEBES USAR LA INFORMACI√ìN DE LOS DOCUMENTOS - NO LA IGNORES
2. Los fragmentos incluyen PREGUNTAS y RESPUESTAS de un banco de preguntas oficiales
3. Si encuentras una respuesta en los documentos, √öSALA directamente
4. NO busques coincidencia EXACTA de palabras - busca SIMILITUD DE SIGNIFICADO
5. Si el documento dice "9 al 14 de febrero" y preguntan "qu√© d√≠a son los votos", RESPONDE con esa fecha
6. NO digas "no tengo informaci√≥n" si la informaci√≥n EST√Å en los fragmentos
7. Solo escala al asesor si la pregunta es COMPLETAMENTE AJENA a NORBOY o cooperativas
8. Responde siempre de manera amable usando "sumerc√©"

EJEMPLOS DE C√ìMO USAR LA INFORMACI√ìN:
- Si preguntan "¬øcu√°ndo es la elecci√≥n?" y el documento dice "Del 9 al 14 de febrero de 2026", responde: "Sumerc√©, la elecci√≥n es del 9 al 14 de febrero de 2026"
- Si preguntan "¬øqu√© d√≠a se vota?" y el documento menciona "votaci√≥n: 9 al 14 de febrero", responde con esa fecha
- Si la informaci√≥n est√°, √∫sala. NO busques excusas para no responder.`;
    } else {
      // Contexto de baja calidad: a√∫n as√≠ intentar usar la informaci√≥n
      promptContext = `üìö INFORMACI√ìN DE DOCUMENTOS DISPONIBLE:\n${context}\n\nINSTRUCCIONES:
1. PRIORIDAD M√ÅXIMA: Usa PRIMERO la informaci√≥n de los documentos proporcionados arriba
2. Aunque la similitud no sea perfecta, si encuentras informaci√≥n relacionada, √öSALA
3. NO busques coincidencia EXACTA - busca SIMILITUD DE SIGNIFICADO
4. Si preguntan por "votos" y el documento menciona "elecci√≥n" o "votaci√≥n", es LO MISMO - usa esa info
5. Solo si NO HAY NADA RELACIONADO despu√©s de revisar TODO, di: "Estamos verificando esa informaci√≥n. Un asesor te contestar√° en breve."
6. Responde siempre de manera amable usando "sumerc√©" para dirigirte al usuario

IMPORTANTE - NO SEAS TAN EXIGENTE:
- NO busques coincidencia PERFECTA de palabras
- "Votaci√≥n" = "Elecci√≥n" = "Votos" = SIN√ìNIMOS - √∫salos como iguales
- Si el documento tiene una fecha, √∫sala aunque la pregunta no sea id√©ntica
- Es mejor responder con informaci√≥n aproximada que decir "no tengo informaci√≥n"`;
    }

    messages.push({
      role: 'system',
      content: promptContext
    });
  } else {
    // Si no hay contexto de documentos, permitir respuestas m√°s generales sobre NORBOY
    messages.push({
      role: 'system',
      content: `üìã BASE DE CONOCIMIENTO:\nNo hay documentos espec√≠ficos cargados.\n\nINSTRUCCIONES:
1. Responde preguntas generales sobre NORBOY (cooperativa, proceso electoral, delegados)
2. Si la pregunta requiere informaci√≥n espec√≠fica (fechas, montos, detalles), di: "Estamos verificando esa informaci√≥n. Un asesor te contestar√° en breve."
3. Si la pregunta es sobre temas completamente ajenos a NORBOY, indica amablemente que un asesor le ayudar√°
4. Responde siempre de manera amable usando "sumerc√©" para dirigirte al usuario

NO respondas sobre temas ajenos a la cooperativa (ciencia, historia, geograf√≠a, clima, etc.).`
    });
  }

  for (const msg of history) {
    messages.push({ role: msg.role, content: msg.content });
  }

  messages.push({ role: 'user', content: userMessage });

  return messages;
};

/**
 * Obtiene el historial de conversaci√≥n del d√≠a actual
 *
 * @param {string} userId - ID del usuario
 * @returns {Array} Historial de mensajes del d√≠a en formato OpenAI
 */
const getConversationHistory = async (userId) => {
  try {
    // Obtener el servicio de estado de conversaci√≥n
    const conversationStateService = require('./conversation-state.service');
    const conversation = conversationStateService.getConversation(userId);

    if (!conversation || !conversation.messages || conversation.messages.length === 0) {
      return [];
    }

    // Obtener mensajes de hoy (√∫ltimas 24 horas)
    const now = Date.now();
    const oneDayMs = 24 * 60 * 60 * 1000;
    const todayStart = now - oneDayMs;

    // Filtrar mensajes de hoy y convertirlos al formato de OpenAI
    const todayMessages = conversation.messages
      .filter(msg => msg.timestamp >= todayStart)
      .map(msg => {
        // Mapear sender a role
        let role = 'user';
        if (msg.sender === 'bot' || msg.sender === 'admin') {
          role = 'assistant';
        }

        return {
          role: role,
          content: msg.message
        };
      });

    logger.debug(`üìú Historial cargado para ${userId}: ${todayMessages.length} mensajes de hoy`);

    return todayMessages;
  } catch (error) {
    logger.error(`Error obteniendo historial de conversaci√≥n para ${userId}:`, error);
    return [];
  }
};

/**
 * Obtiene informaci√≥n por categor√≠a
 */
const getInfoByCategory = (category) => {
  const items = knowledgeBase.getByCategory(category);
  if (items.length === 0) return null;
  return items.map(item => `‚Ä¢ ${item.question}\n  ${item.answer}`).join('\n\n');
};

/**
 * Lista categor√≠as disponibles
 */
const getAvailableCategories = () => {
  return knowledgeBase.getCategories();
};

module.exports = {
  generateTextResponse,
  getConversationHistory,
  buildMessages,
  getInfoByCategory,
  getAvailableCategories,
  cleanQuestionMarks,
  hasUserConsent,
  setConsentResponse,
  resetUserInteractions,
  getUserInteractionCount,
  getPendingMessage,
  clearPendingMessage,
  resetUserState,
  getEscalationMessage,
  getOutOfHoursMessage,
  NO_INFO_MESSAGE  // Exportar para uso en otros m√≥dulos
};
